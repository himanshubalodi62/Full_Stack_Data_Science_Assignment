{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7681453",
   "metadata": {},
   "source": [
    "#### 1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "\n",
    "### Ans:\n",
    "\n",
    "TensorFlow is an open-source library developed by Google primarily for deep learning applications. TensorFlow accepts data in the form of multi-dimensional arrays of higher dimensions called tensors. Multi-dimensional arrays are very handy in handling large amounts of data. TensorFlow works on the basis of data flow graphs that have nodes and edges. As the execution mechanism is in the form of graphs, it is much easier to execute TensorFlow code in a distributed manner across a cluster of computers while using GPUs.\n",
    "\n",
    "#### Main features of Tensorflow\n",
    "\n",
    "#### a. Responsive Construct\n",
    "\n",
    "With TensorFlow we can easily visualize each and every part of the graph which is not an option while using Numpy or SciKit.\n",
    "\n",
    "#### b. Flexible\n",
    "\n",
    "One of the very important Tensorflow Features is that it is flexible in its operability, meaning it has modularity and the parts of it which you want to make standalone, it offers you that option.\n",
    "\n",
    "#### c. Easily Trainable\n",
    "\n",
    "It is easily trainable on CPU as well as GPU for distributed computing.\n",
    "\n",
    "#### d. Parallel Neural Network Training\n",
    "\n",
    "TensorFlow offers pipelining in the sense that you can train multiple neural networks and multiple GPUs which makes the models very efficient on large-scale systems.\n",
    "\n",
    "#### e. Large Community\n",
    "\n",
    "Needless to say, if it has been developed by Google, there already is a large team of software engineers who work on stability improvements continuously.\n",
    "\n",
    "#### f. Open Source\n",
    "\n",
    "The best thing about this machine learning library is that it is open source so anyone can use it as long as they have internet connectivity. So, people manipulate the library in ways unimaginable and come up with an amazing variety of useful products, it has become another DIY community which has a huge forum for people getting started with it and for those who find it hard to use it or to get help with their work.\n",
    "\n",
    "#### g. Feature Columns\n",
    "\n",
    "Tensorflow has feature columns that could be thought of as intermediaries between raw data and estimators, therefore, bridging input data with your model.\n",
    "\n",
    "#### h. Availability of Statistical Distributions\n",
    "\n",
    "The library provides distribution functions including Bernoulli, Beta, Chi2, Uniform, Gamma, which are important especially while considering probabilistic approaches such as Bayesian models.\n",
    "\n",
    "#### i. Layered Components\n",
    "\n",
    "TensorFlow includes functions like tf.contrib.layers that produce layered operations of weights and biases and also provide batch normalization, convolution layer, dropout layer, etc. So tf.contrib.layers.optimizers has optimizers such as Adagrad, SGD, Momentum which are often used to solve optimization problems for numerical analysis, it provides initializers with tf.contrib.layers.initializers used to maintain the gradient scale. This type of TensorFlow Features makes it what it is today.\n",
    "\n",
    "#### j. Visualizer (with TensorBoard)\n",
    "\n",
    "With TensorBoard you can inspect a totally different representation of a model and make the changed necessary while debugging it.\n",
    "\n",
    "#### k. Event Logger (with TensorBoard)\n",
    "\n",
    "So, just like UNIX, where you use tail –f <log_file > to monitor the output of tasks at the cmd and do quick checks, logging events in Tensorflow allows doing the same by logging events and summaries from the graph and the output over time with TensorBoard.\n",
    "\n",
    "#### Other Deep Learning frameworks are :\n",
    "\n",
    "PyTorch is built with Python and has many other similarities to TensorFlow: hardware-accelerated components under the hood, a highly interactive development model that allows for design-as-you-go work, and many useful components already included. PyTorch is generally a better choice for fast development of projects that need to be up and running in a short time, but TensorFlow wins out for larger projects and more complex workflows.\n",
    "\n",
    "CNTK, the Microsoft Cognitive Toolkit, is like TensorFlow in using a graph structure to describe dataflow, but it focuses mostly on creating deep learning neural networks. CNTK handles many neural network jobs faster, and has a broader set of APIs (Python, C++, C#, Java). But it isn’t currently as easy to learn or deploy as TensorFlow. It's also only available under the GNU GPL 3.0 license, whereas TensorFlow is available under the more liberal Apache license. And CNTK isn't as aggressively developed; the last major release was in 2019.\n",
    "\n",
    "Apache MXNet, adopted by Amazon as the premier deep learning framework on AWS, can scale almost linearly across multiple GPUs and multiple machines. MXNet also supports a broad range of language APIs—Python, C++, Scala, R, JavaScript, Julia, Perl, Go—although its native APIs aren’t as pleasant to work with as TensorFlow’s. It also has a far smaller community of users and developers.\n",
    "\n",
    "\n",
    "#### 2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "No Tensorflow is not a drop-in replacement for Numpy.\n",
    "\n",
    "Tensorflow is a library for artificial intelligence, especially machine learning. Numpy is a library for doing numerical calculations. They are often used in combination, because it's often required to pre-process data, which can be done with NumPy, and then do the machine learning on the processed data with Tensorflow.\n",
    "\n",
    "Pandas, MATLAB, R Language, SciPy, and Panda are the most popular alternatives and competitors to NumPy.\n",
    "\n",
    "Generally, we use NumPy for working with an array and TensorFlow for working with a tensor. The difference between a NumPy array and a tensor is that the tensors are backed by the accelerator memory like GPU and they are immutable, unlike NumPy arrays.\n",
    "\n",
    "\n",
    "#### 3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "Yes, we get same result with tf.range(10) and tf.constant(np.arange(10)).\n",
    "\n",
    "#### 4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "\n",
    "### Ans: \n",
    "\n",
    "#### Here are six such data structures:\n",
    "\n",
    "**1. SparseTensor:** A SparseTensor represents a tensor where most of the elements are zeros. It is useful when dealing with sparse data, such as text or graph data, where only a small portion of the data is non-zero. SparseTensors store the non-zero values along with their indices, enabling efficient computation and storage.\n",
    "\n",
    "**2.Variable:** Variables are mutable tensors that can hold values that can be updated during training. They are commonly used to represent model parameters or any other values that need to be optimized. Variables are initialized with an initial value and can be updated using operations like gradient descent.\n",
    "\n",
    "**3.Dataset:** The Dataset API in TensorFlow provides a way to represent and manipulate large datasets efficiently. It allows you to create a pipeline for loading, preprocessing, and batching data for training or inference. Datasets can be created from various sources such as in-memory data, files, or database connections.\n",
    "\n",
    "**4.Queue:** TensorFlow provides several types of queues that can be used for asynchronous data loading and preprocessing. Queues allow you to decouple the data loading process from the computation, enabling efficient parallel processing. The QueueRunner and Coordinator classes can be used to manage the queue operations.\n",
    "\n",
    "**5.RaggedTensor:** A RaggedTensor is a tensor with non-uniform shapes. It is useful for representing sequences or nested data structures where the lengths can vary. RaggedTensors can be used to efficiently represent and process data like sentences with varying numbers of words or batches of sequences with different lengths.\n",
    "\n",
    "**6. SparseFeature:** SparseFeature is a data structure used for handling sparse features in TensorFlow. It provides a way to represent and process sparse features efficiently, such as categorical features with a large number of possible values. SparseFeatures can be used in conjunction with dense tensors to build models that handle both dense and sparse input data.\n",
    "\n",
    "5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Using Keras Custom Object Scopes to work, your custom losses should be defined as subclasses of tf.keras.losses.Loss and not as functions. If you define custom losses as functions def tversky_fn(y_true, y_pred) then in the computational graph it will just be called loss and val_loss and you wont be able to distinguish between tversky and dice losses.\n",
    "\n",
    "Your custom object scope can look like.\n",
    "\n",
    "class TverskyLoss(tf.keras.losses.Loss):\n",
    "\n",
    "def init(self, beta, num_classes)\n",
    "\n",
    "##### The implementation of the loss\n",
    "\n",
    "class DiceLoss(tf.keras.losses.Loss): def init(self, num_classes)\n",
    "\n",
    "The implementation of the loss\n",
    "...\n",
    "...\n",
    "def build_model(hp): custom_objects = [\n",
    "\n",
    "    {\"TverskyLoss\": TverskyLoss, \"config\": {\"beta\": 0.5, \"num_classes\": 10, \"name\": \"tversky_loss\"}},\n",
    "\n",
    "    {\"DiceLoss\": DiceLoss, \"config\": {\"num_classes\": 10, \"name\": \"dice_loss\"}}\n",
    "\n",
    "]\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "\n",
    "####  #Now build the model and call model.compile\n",
    "\n",
    "\n",
    "#### 6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "A metric is a function that is used to judge the performance of your model.\n",
    "\n",
    "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n",
    "\n",
    "#### 7. When should you create a custom layer versus a custom model?\n",
    "\n",
    "Ans:\n",
    "\n",
    "If you are building a new model architecture using existing keras/tf layers then build a custom model. If you are implementing your own custom tensor operations with in a layer, then build a custom layer.\n",
    "\n",
    "#### 8. What are some use cases that require writing your own custom training loop?\n",
    "\n",
    "Ans:\n",
    "\n",
    "+ Customize deep learning training loops and loss functions. If the trainingOptions function does not provide the training options that you need for your task, or custom output layers do not support the loss functions that you need, then you can define a custom training loop.\n",
    "\n",
    "\n",
    "#### 9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "They should be convertible to TF Functions. If you need to use arbitrary Python code, wrap it in tf. py_function() or set dynamic=True when creating the custom layer or model.\n",
    "\n",
    "#### 10. What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "tf.function is a decorator function provided by Tensorflow 2.0 that converts regular python code to a callable Tensorflow graph function, which is usually more performant and python independent. It is used to create portable Tensorflow models.\n",
    "\n",
    "#### 11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "\n",
    "\n",
    "You would need to create a dynamic Keras model when the structure or architecture of the model needs to change dynamically during runtime based on certain conditions or inputs. This can be useful in scenarios where you have varying input shapes, varying number of layers, or conditional branching within the model.\n",
    "\n",
    "To create a dynamic Keras model, you can use the Functional API or the Subclassing API provided by Keras. The Functional API allows you to define complex models by connecting layers in a directed acyclic graph, while the Subclassing API enables you to define custom layers and models as Python classes.\n",
    "\n",
    "Not all models need to be dynamic because in many cases, the structure of the model is fixed and known beforehand. Dynamic models come with additional complexity and can be harder to train and optimize compared to static models. Therefore, it is recommended to use dynamic models only when necessary, such as in cases where the model architecture needs to adapt dynamically to varying inputs or conditions.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363d2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
