{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb2166b",
   "metadata": {},
   "source": [
    "#### 1. Why would you want to use the Data API?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "APIs are needed to bring applications together in order to perform a designed function built around sharing data and executing pre-defined processes. They work as the middle man, allowing developers to build new programmatic interactions between the various applications people and businesses use on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77cd52",
   "metadata": {},
   "source": [
    "#### 2. What are the benefits of splitting a large dataset into multiple files?\n",
    "\n",
    "#### Ans:\n",
    "The key benefits of splitting a large dataset into multiple files are :\n",
    "\n",
    "1. Multiple Users can Access Data Simultaneously\n",
    "\n",
    "2. Provides Better Protection\n",
    "\n",
    "3. Allows for Future Planning\n",
    "\n",
    "4. Easy to Modify User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29d5da",
   "metadata": {},
   "source": [
    "#### 3. During training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?\n",
    "\n",
    "### Ans:\n",
    "\n",
    "You can use TensorBoard to visualize profiling data: if the GPU is not fully utilized then your input pipeline is likely to be the bottleneck. -You can fix it by making sure it reads and preprocesses the data in multiple threads in parallel, and ensuring it prefetches a few batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad600520",
   "metadata": {},
   "source": [
    "#### 4. Can you save any binary data to a TFRecord file, or only serialized protocol buffers?\n",
    "\n",
    "### Ans:\n",
    "\n",
    "Yes we can store any binary data to TFRecord file. Because the TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e528b6",
   "metadata": {},
   "source": [
    "#### 5. Why would you go through the hassle of converting all your data to the Example protobuf format? Why not use your own protobuf definition?\n",
    "\n",
    "#### Ans:\n",
    "\n",
    "Protocol buffers format provides a language-neutral, platform-neutral, extensible mechanism for serializing structured data in a forward-compatible and backward-compatible way. It’s like JSON, except it’s smaller and faster, and it generates native language bindings.\n",
    "\n",
    "Unlike other formats, nested Protobuf messages cannot be written contiguously into a stream without significant buffering. The post doesn't argue to never use Protobuf, but that the trade-off made by the wire-format itself, as opposed to any existing implementation, is unlikely to work for lightweight message senders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c27379",
   "metadata": {},
   "source": [
    "#### 6. When using TFRecords, when would you want to activate compression? Why not do it systematically?\n",
    "\n",
    "#### Ans:  Activating compression when using TFRecords can be beneficial in certain scenarios, depending on factors such as the size of the data, storage limitations, and the trade-off between compression and performance.\n",
    "\n",
    "Here are a few situations where enabling compression in TFRecords can be advantageous:\n",
    "\n",
    "+ Reducing storage space: If you have a large dataset, enabling compression can significantly reduce the disk space required to store the TFRecords. This can be especially useful when dealing with massive datasets or when storage space is limited.\n",
    "\n",
    "+ Network transfer: If you need to transfer the TFRecords over a network, enabling compression can reduce the amount of data that needs to be transmitted, resulting in faster transfer times and reduced bandwidth usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ce5f5",
   "metadata": {},
   "source": [
    "#### 7. Data can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model, or using TF Transform. Can you list a few pros and cons of each option?\n",
    "\n",
    "Ans:\n",
    "Here are some pros and cons of each option for preprocessing data:\n",
    "\n",
    "#### 1. Preprocessing during data file writing:\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "+ Allows for one-time preprocessing and data transformation before training.\n",
    "+ Preprocessed data can be easily shared and reused across different models or experiments.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "+ Lack of flexibility to adapt preprocessing based on model changes or updates.\n",
    "+ Preprocessed data files can take up additional storage space.\n",
    "\n",
    "\n",
    "#### 2. Preprocessing within the tf.data pipeline:\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "+ Provides flexibility to apply dynamic and on-the-fly preprocessing based on model requirements.\n",
    "+ Allows for efficient data loading and preprocessing in a single pipeline.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "+ Can introduce additional computational overhead during training if complex preprocessing operations are performed.\n",
    "\n",
    "+ Preprocessing logic needs to be repeated for each training run, potentially affecting reproducibility.\n",
    "\n",
    "\n",
    "The choice of where to preprocess data depends on factors such as the nature of the preprocessing operations, data size, reusability requirements, and trade-offs between flexibility and computational efficiency. Each option has its own advantages and drawbacks, and the decision should be based on the specific needs of the project or model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5691266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
